# configs/dpo_gpt2.yaml
# DPO config for rlhf-lab (default: small-local experiment)
# Target: single-GPU / workstation experiments (distilgpt2 / gpt2-small).
# For larger runs change model_name_or_path and scale batch/steps accordingly.

# ---------------------------
# Model & Tokenizer
# ---------------------------
model:
  model_name_or_path: "distilgpt2"        # small model for local runs; swap to "gpt2" or larger as needed
  tokenizer_name_or_path: null            # null -> use model_name_or_path
  trust_remote_code: false
  local_files_only: false                 # set true if offline
  load_in_8bit: false                     # requires bitsandbytes if true
  use_peft: false
  peft_adapter_path: null                 # if using LoRA/PEFT, put adapter path here
  # Max length used for tokenization/score calls
  max_length: 256

# ---------------------------
# Data
# ---------------------------
data:
  train_file: "data/pref_pairs.jsonl"     # JSONL lines: {"prompt":"...","chosen":"...","rejected":"..."}
  val_file: "data/pref_pairs_val.jsonl"   # optional validation file (same format)
  max_items: null                         # limit samples for smoke tests (null => all)
  shuffle: true

# ---------------------------
# Training / DPO specifics
# ---------------------------
training:
  out_dir: "checkpoints/dpo"
  per_device_train_batch_size: 4          # batch size in dataloader (samples per step)
  gradient_accumulation_steps: 1
  num_train_epochs: 3
  max_steps: null                         # if set, overrides epoch-based stopping
  logging_steps: 50
  save_steps: 500
  eval_steps: 200
  seed: 42

# DPO hyperparameters
dpo:
  # DPO objective uses reference model logprobs (kappa) and current policy logprobs.
  # No explicit clip epsilon (that's PPO), but we include small stability options.
  loss_eps: 1e-12                         # numerical stability for sigmoid/log
  l2_weight: 0.0                          # optional L2 reg on parameters
  positive_margin: null                   # optional margin threshold (null => standard DPO)

# ---------------------------
# Optimizer & scheduler
# ---------------------------
optim:
  learning_rate: 2e-05
  weight_decay: 0.0
  adam_eps: 1e-08
  betas: [0.9, 0.999]
  max_grad_norm: 1.0

scheduler:
  use_scheduler: true
  scheduler_type: "linear"     # linear | cosine | cosine_with_restarts
  warmup_steps: 100
  total_training_steps: 10000  # used by scheduler if provided (optional)

# ---------------------------
# Mixed Precision & Device
# ---------------------------
runtime:
  device: "cuda"               # "cuda" or "cpu"
  fp16: true                   # use AMP on CUDA
  local_files_only: false

# ---------------------------
# Reference policy
# ---------------------------
reference:
  reference_model_name_or_path: null   # if null -> clone policy at start (common choice)
  # If you want to use a separate tokenizer for the reference model, specify here:
  reference_tokenizer_name_or_path: null

# ---------------------------
# PEFT / LoRA (optional)
# ---------------------------
peft:
  enabled: false
  lora_r: 8
  lora_alpha: 32
  lora_dropout: 0.05
  target_modules: ["c_attn", "q_proj", "v_proj", "k_proj"]

# ---------------------------
# Checkpointing & Logging
# ---------------------------
logging:
  out_dir: "checkpoints/dpo"
  save_total_limit: 5
  log_level: "INFO"
  log_file: "checkpoints/dpo/training.log"
  use_wandb: false
  wandb_project: "rlhf-dpo"
  wandb_entity: null

# ---------------------------
# Evaluation
# ---------------------------
eval:
  evaluate_during_training: true
  eval_batch_size: 8
  # Automatic eval metrics (keeps it minimal locally)
  compute_pairwise_accuracy: true
  compute_mean_margin: true
  sample_eval_pairs: 200

# ---------------------------
# Debug / Misc
# ---------------------------
misc:
  smoke_test_mode: false            # if true runs tiny subset for quick debug
  debug_num_steps: 50
  deterministic: false

# ---------------------------
# Notes
# - Make sure `data/pref_pairs.jsonl` exists (see example below).
# - For local runs set fp16:false if you don't have CUDA.
# - For large-scale or multi-node, integrate with accelerate and set device_map / load_in_8bit appropriately.

